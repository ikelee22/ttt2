{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.anadronestarting.com/wp-content/uploads/intel-main_opt.png' width=50%>\n",
    "\n",
    "# 모바일넷을 이용한 이미지분류\n",
    "<font size=5><b>(Image Classification using Mobilenet)<b></font>\n",
    "\n",
    "<div align='right'>성  민  석 (Minsuk Sung)</div>\n",
    "<div align='right'>이  인  구 (Ike Lee)</div>    \n",
    "\n",
    "<img src='https://chaosmail.github.io/images/deep-learning/classification.png' width=60%>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>강의목차<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#필요한-라이브러리-및-옵션\" data-toc-modified-id=\"필요한-라이브러리-및-옵션-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>필요한 라이브러리 및 옵션</a></span><ul class=\"toc-item\"><li><span><a href=\"#기본-라이브러리(Library)\" data-toc-modified-id=\"기본-라이브러리(Library)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>기본 라이브러리(Library)</a></span></li><li><span><a href=\"#옵션(Option)\" data-toc-modified-id=\"옵션(Option)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>옵션(Option)</a></span></li></ul></li><li><span><a href=\"#예제---VOC2012\" data-toc-modified-id=\"예제---VOC2012-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>예제 - VOC2012</a></span><ul class=\"toc-item\"><li><span><a href=\"#VOC-2012란?\" data-toc-modified-id=\"VOC-2012란?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>VOC 2012란?</a></span></li><li><span><a href=\"#VOC-데이터의-구성\" data-toc-modified-id=\"VOC-데이터의-구성-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>VOC 데이터의 구성</a></span></li><li><span><a href=\"#다운로드-링크\" data-toc-modified-id=\"다운로드-링크-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>다운로드 링크</a></span></li><li><span><a href=\"#학습에-필요한-상수\" data-toc-modified-id=\"학습에-필요한-상수-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>학습에 필요한 상수</a></span></li><li><span><a href=\"#모델-컴파일\" data-toc-modified-id=\"모델-컴파일-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>모델 컴파일</a></span></li><li><span><a href=\"#모델-학습하기\" data-toc-modified-id=\"모델-학습하기-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>모델 학습하기</a></span></li><li><span><a href=\"#모델-저장하기\" data-toc-modified-id=\"모델-저장하기-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>모델 저장하기</a></span></li><li><span><a href=\"#모델-평가하기\" data-toc-modified-id=\"모델-평가하기-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>모델 평가하기</a></span></li><li><span><a href=\"#테스트해보기\" data-toc-modified-id=\"테스트해보기-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>테스트해보기</a></span></li></ul></li><li><span><a href=\"#참고\" data-toc-modified-id=\"참고-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>참고</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 및 옵션\n",
    "\n",
    "### 기본 라이브러리(Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:28.994832Z",
     "start_time": "2019-12-02T14:36:28.983647Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:29.526976Z",
     "start_time": "2019-12-02T14:36:28.997413Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:29.714954Z",
     "start_time": "2019-12-02T14:36:29.528764Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.483839Z",
     "start_time": "2019-12-02T14:36:29.716050Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist,cifar10\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, MobileNetV2\n",
    "from tensorflow.keras.models import Model,Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Conv2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.losses import categorical_crossentropy,binary_crossentropy\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵션(Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.613864Z",
     "start_time": "2019-12-02T14:36:30.484987Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "%matplotlib inline\n",
    "print(device_lib.list_local_devices())\n",
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 예제 - VOC2012\n",
    "\n",
    "![](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/pascal2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOC 2012란?\n",
    "VOC2012 : Visual Object Classes Challenge 2012 (VOC2012)\n",
    "\n",
    "### VOC 데이터의 구성\n",
    "PASCAL VOC Dataset을 다운받아 압축을 풀면 다음과 같은 구조를 확인할 수 있습니다.\n",
    "```\n",
    "VOC2012\n",
    "├── Annotations\n",
    "│   ├── 2010_000002.xml\n",
    "│   ├── 2010_000003.xml\n",
    "│   ├── 2011_000002.xml\n",
    "│   └── ...\n",
    "├── ImageSets\n",
    "│   ├── Action\n",
    "│   ├── Layout\n",
    "│   ├── Main\n",
    "│   └── Segmentation\n",
    "├── JPEGImages\n",
    "│   ├── 2010_000002.jpg\n",
    "│   ├── 2010_000003.jpg\n",
    "│   ├── 2011_000002.jpg\n",
    "│   └── ...\n",
    "├── SegmentationClass\n",
    "│   ├── 2010_000002.png\n",
    "│   ├── 2010_000003.png\n",
    "│   └── 2011_000003.png\n",
    "└── SegmentationObject\n",
    "    ├── 2010_000002.png\n",
    "    ├── 2010_000003.png\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "- Annotations : JPEGImages 폴더 속 원본 이미지와 같은 이름들의 xml파일들이 존재합니다. Object Detection을 위한 정답 데이터이 됩니다.\n",
    "\n",
    "- ImageSets : 어떤 이미지 그룹을 test, train, trainval, val로 사용할 것인지, 특정 클래스가 어떤 이미지에 있는지 등에 대한 정보들을 포함하고 있는 폴더입니다.\n",
    "\n",
    "- JPEGImages : jpg확장자를 가진 이미지 파일들이 모여있는 폴더입니다. Object Detection에서 입력 데이터가 됩니다.\n",
    "\n",
    "- SegmentationClass : Semantic segmentation을 학습하기 위한 label 이미지입니다.\n",
    "\n",
    "- SegmentationObject : Instance segmentation을 학습하기 위한 label 이미지입니다.\n",
    "\n",
    "Object Detection을 할 때는 주로 Annotations, JPEGImages폴더가 사용됩니다. 모델에 입력으로 넣는 입력데이터인 경우 그냥 load 해서 사용하면 되나, 지도학습에 핵심이 되는 정답 데이터의 경우는 parsing이 필요한 경우가 있으므로 Annotations의 xml 구조는 잘 알아두는 것이 중요합니다.\n",
    "\n",
    "출처 : https://deepbaksuvision.github.io/Modu_ObjectDetection/posts/02_01_PASCAL_VOC.html\n",
    "\n",
    "### 다운로드 링크\n",
    "- http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "- https://pjreddie.com/projects/pascal-voc-dataset-mirror/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> VOC 2012 데이터는 한 이미지 내에 여러가지 객체가 존재합니다. 그래서 기존의 방법과는 조금 다르게 접근해야합니다.  \n",
    "아래 코드를 따라가봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.617087Z",
     "start_time": "2019-12-02T14:36:30.614844Z"
    }
   },
   "outputs": [],
   "source": [
    "# 우리가 분류할 20개의 클래스\n",
    "\n",
    "CLASSES = ['person',  # Person\n",
    "           'bird', 'cat', 'cow', 'dog', 'horse', 'sheep', # Animal\n",
    "           'aeroplane', 'bicycle', 'boat', 'bus', 'car', 'motorbike', 'train', # Vehicle\n",
    "           'bottle', 'chair', 'dining table', 'potted plant', 'sofa', 'tv monitor' # Indoor\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습에 필요한 상수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:30.621898Z",
     "start_time": "2019-12-02T14:36:30.618645Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습에 필요한 상수들을 정의 합니다. \n",
    "\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "\n",
    "# 각 이미지의 기본 주소\n",
    "BASE_PATH = './data/VOC2012/JPEGImages/'\n",
    "images_dir = Path(BASE_PATH).expanduser()\n",
    "print(images_dir)\n",
    "\n",
    "# 각 이미지별 클래스의 기본 주소\n",
    "XML_BASE_PATH = './data/VOC2012/Annotations/'\n",
    "annotations_dir = Path(XML_BASE_PATH).expanduser()\n",
    "print(annotations_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:31.556568Z",
     "start_time": "2019-12-02T14:36:30.623333Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#입력 데이터를 렌덤하게 받아서 데이터 포멧을 확인 합니다. \n",
    "\n",
    "flist = glob.glob(BASE_PATH+'*.jpg')\n",
    "idx = np.random.randint(0,len(flist))\n",
    "fpath = flist[idx]\n",
    "img = cv2.imread(fpath)\n",
    "fname = os.path.basename(fpath).split('.')[0]\n",
    "\n",
    "image = Image.open(fpath).convert(\"RGB\")\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "xml = open(XML_BASE_PATH+fname+'.xml', \"r\")\n",
    "tree = ET.parse(xml)\n",
    "root = tree.getroot()\n",
    "\n",
    "size = root.find(\"size\")\n",
    "\n",
    "width = size.find(\"width\").text\n",
    "height = size.find(\"height\").text\n",
    "channels = size.find(\"depth\").text\n",
    "\n",
    "print('-'*50)\n",
    "print(\"Image properties\")\n",
    "print('-'*50)\n",
    "print('File : {}'.format(fpath))\n",
    "print(\"width : {}\\nheight : {}\\nchannels : {}\\n\".format(width, height, channels))\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "objects = root.findall(\"object\")\n",
    "print('-'*50)\n",
    "print(\"Objects Description\")\n",
    "print('-'*50)\n",
    "for _object in objects:\n",
    "    name = _object.find(\"name\").text\n",
    "    bndbox = _object.find(\"bndbox\")\n",
    "    xmin = int(bndbox.find(\"xmin\").text)\n",
    "    ymin = int(bndbox.find(\"ymin\").text)\n",
    "    xmax = int(bndbox.find(\"xmax\").text)\n",
    "    ymax = int(bndbox.find(\"ymax\").text)\n",
    "    \n",
    "    # Box를 그릴 때, 왼쪽 상단 점(xmin,ymin)과, 오른쪽 하단 점의 좌표(xmax,ymax)를 입력으로 주면 됩니다.\n",
    "    draw.rectangle(((xmin, ymin), (xmax, ymax)), outline=\"yellow\",width=3)\n",
    "    draw.text((xmin, ymin-10), name,align='center')\n",
    "\n",
    "    print(\"class : {:3}\\nxmin : {:3}, ymin : {:3}\\nxmax : {:3}, ymax : {:3}\\n\".format(name, xmin, ymin, xmax, ymax))\n",
    "\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:31.561582Z",
     "start_time": "2019-12-02T14:36:31.557588Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 레이블을 정리 합니다 \n",
    "\n",
    "def xml_to_labels(xml_data, unique_labels):\n",
    "    root = ET.XML(xml_data)\n",
    "    labels = set() if unique_labels else []\n",
    "    labels_add = labels.add if unique_labels else labels.append # speeds up method lookup\n",
    "    for i, child in enumerate(root):\n",
    "        if child.tag == 'filename':\n",
    "            img_filename = child.text\n",
    "        if child.tag == 'object':\n",
    "            for subchild in child:\n",
    "                if subchild.tag == 'name':\n",
    "                    labels_add(subchild.text)\n",
    "    return img_filename, list(labels)\n",
    "\n",
    "def get_labels(annotations_dir, unique_labels=True):\n",
    "    for annotation_file in annotations_dir.iterdir():\n",
    "        with open(annotation_file) as f:\n",
    "            yield xml_to_labels(f.read(), unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:35.329392Z",
     "start_time": "2019-12-02T14:36:31.562740Z"
    }
   },
   "outputs": [],
   "source": [
    "# img_metadata = pd.DataFrame(get_labels(annotations_dir), columns=['filename', 'labels'])\n",
    "# print('Found {} images'.format(len(img_metadata)))\n",
    "# img_metadata.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:35.743016Z",
     "start_time": "2019-12-02T14:36:35.331202Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_labels = [label for lbs in img_metadata['labels'] for label in lbs]\n",
    "# labels_count = Counter(all_labels)\n",
    "# ax = sns.countplot(all_labels, order=[k for k, _ in labels_count.most_common()], log=True)\n",
    "# ax.set_title('Number of images with a class label')\n",
    "# ax.set_ylim(1E2, 1E4)\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:43.911359Z",
     "start_time": "2019-12-02T14:36:35.744093Z"
    }
   },
   "outputs": [],
   "source": [
    "# height, width, size = np.empty(len(img_metadata)), np.empty(len(img_metadata)), np.empty(len(img_metadata)) \n",
    "# for i, img_filepath in img_metadata['filename'].iteritems():\n",
    "#     w, h = Image.open(images_dir.joinpath(img_filepath)).size\n",
    "#     width[i], height[i], size[i] = w, h, w * h * 3 * 1E-6\n",
    "# plt.scatter(width, height, alpha=0.5)\n",
    "# plt.xlabel('Width'); plt.ylabel('Height'); plt.show()\n",
    "# plt.hist(size, bins=50, log=True)\n",
    "# plt.xlabel('Image size (MB)');\n",
    "# plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:44.072012Z",
     "start_time": "2019-12-02T14:36:43.912394Z"
    }
   },
   "outputs": [],
   "source": [
    "# 우리가 모델 훈련에 사용할 데이터 내용 입니다.\n",
    "\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "IMAGE_BASE_PATH = './data/VOC4IC/'\n",
    "train_path = IMAGE_BASE_PATH + 'train/'\n",
    "for folder in os.listdir(train_path):\n",
    "    folder_size = len(os.listdir(train_path+folder))\n",
    "#     print('{:<15} : {}'.format(folder,folder_size))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "    \n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 모델 훈련 검증에 사용할 데이터 내용 입니다.\n",
    "\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "IMAGE_BASE_PATH = './data/VOC4IC/'\n",
    "valid_path = IMAGE_BASE_PATH + 'valid/'\n",
    "for folder in os.listdir(valid_path):\n",
    "    folder_size = len(os.listdir(valid_path+folder))\n",
    "#     print('{:<15} : {}'.format(folder,folder_size))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "    \n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:44.285382Z",
     "start_time": "2019-12-02T14:36:44.073088Z"
    }
   },
   "outputs": [],
   "source": [
    "# 우리가 훈련된 모델을 검증하는데 사용할 데이터 내용 입니다.\n",
    "\n",
    "class_list = []\n",
    "num_list = []\n",
    "\n",
    "IMAGE_BASE_PATH = './data/VOC4IC/'\n",
    "test_path = IMAGE_BASE_PATH + 'test/'\n",
    "for folder in os.listdir(test_path):\n",
    "    folder_size = len(os.listdir(test_path+folder))\n",
    "#     print('{:<15} : {}'.format(folder,folder_size))\n",
    "    class_list.append(folder)\n",
    "    num_list.append(folder_size)\n",
    "    \n",
    "voc_s = pd.Series(num_list,index=class_list)\n",
    "voc_s.sort_values().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "print(voc_s.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:48.471330Z",
     "start_time": "2019-12-02T14:36:44.286500Z"
    }
   },
   "outputs": [],
   "source": [
    "# base model 의 input shape, 그리고  trainable 을 false 로 합니다. \n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224,224,3),\n",
    "                         include_top=False,\n",
    "                         weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:48.479155Z",
     "start_time": "2019-12-02T14:36:48.472416Z"
    }
   },
   "outputs": [],
   "source": [
    "# transfer learning에서 마지막 3개 block 을 사용하여 모델을 트레이닝 합니다. \n",
    "\n",
    "set_trainable = False\n",
    "for layer in tqdm(base_model.layers):\n",
    "    if layer.name in ['block_14_expand','block_15_expand', 'block_16_expand']:\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:48.489086Z",
     "start_time": "2019-12-02T14:36:48.480044Z"
    }
   },
   "outputs": [],
   "source": [
    "# 레이어 구성을 살펴 봅니다. \n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in base_model.layers]\n",
    "\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:49.976485Z",
     "start_time": "2019-12-02T14:36:48.490018Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 만들기, 기존 모델의 weight 값을 사용하고 pooling 과 activation 함수를 추가 합니다. \n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(len(CLASSES), activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "plot_model(model,to_file='./img/model/voc2012_mobilenet_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.038821Z",
     "start_time": "2019-12-02T14:36:49.977831Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy, \n",
    "              optimizer=Adam(learning_rate=0.0001), # transfer learning 여기서 학습률을 더 작게 \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.152095Z",
     "start_time": "2019-12-02T14:36:50.039930Z"
    }
   },
   "outputs": [],
   "source": [
    "# 트레인 데이터 augmentation 의로 데이터를 증가 시킴니다.  \n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=30,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest'\n",
    "                                   )\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(IMAGE_BASE_PATH + 'train/',\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=8,\n",
    "                                              shuffle=True,\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.513753Z",
     "start_time": "2019-12-02T14:36:50.157114Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습중에 validation에 사용할 데이터셋 입니다.  \n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_set = valid_datagen.flow_from_directory(IMAGE_BASE_PATH + 'valid/',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=8,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:36:50.635869Z",
     "start_time": "2019-12-02T14:36:50.518433Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습을 완료후에 모델 성능 테스트에 사용할 데이터셋 입니다. \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(IMAGE_BASE_PATH + 'test/',\n",
    "                                            target_size=(224, 224),\n",
    "                                            batch_size=8,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:25.137510Z",
     "start_time": "2019-12-02T14:37:10.164914Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 트레이닝 입니다. \n",
    "\n",
    "history = model.fit_generator(train_set,\n",
    "                              steps_per_epoch=train_set.n // train_set.batch_size,\n",
    "                              epochs=1,\n",
    "                              validation_data=valid_set,\n",
    "                              validation_steps=valid_set.n // valid_set.batch_size,\n",
    "#                               use_multiprocessing=True,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:25.906887Z",
     "start_time": "2019-12-02T14:44:25.142704Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./bin/mobilenetv2_class20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.class_indices.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:25.906887Z",
     "start_time": "2019-12-02T14:44:25.142704Z"
    }
   },
   "outputs": [],
   "source": [
    "# key 와 value 값을 바꾸어 줍니다. \n",
    "class20 = dict()\n",
    "for key,value in test_set.class_indices.items():\n",
    "    class20[value] = key\n",
    "\n",
    "with open('./bin/class20.pickle', 'wb') as f:\n",
    "    pickle.dump(class20, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:50.922359Z",
     "start_time": "2019-12-02T14:44:25.908502Z"
    }
   },
   "outputs": [],
   "source": [
    "# 트레인 데이터와 테스트 데이터 셋으로 loss 와 accuracy 측정합니다.  \n",
    "\n",
    "train_loss, train_acc = model.evaluate_generator(train_set)\n",
    "print('Train Loss : {}'.format(train_loss))\n",
    "print('Train Accuracy : {}'.format(train_acc))\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_set)\n",
    "print('Test Loss : {}'.format(test_loss))\n",
    "print('Test Accuracy : {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:51.054839Z",
     "start_time": "2019-12-02T14:44:50.923838Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss 측정값의 시각화 입니다.  \n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,loss,label='Training Loss')\n",
    "plt.plot(epochs,val_loss,label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:51.178139Z",
     "start_time": "2019-12-02T14:44:51.055902Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy 측정값의 시각화 입니다.  \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.plot(epochs,acc,label='Training Accuarcy')\n",
    "plt.plot(epochs,val_acc,label='Validation Accuarcy')\n",
    "plt.title('Training and Validation Accuarcy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuarcy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:44:55.300576Z",
     "start_time": "2019-12-02T14:44:55.290471Z"
    }
   },
   "outputs": [],
   "source": [
    "# 추론하기 위한 작업입니다. 모델 설정, 입력 데이터 전처리.\n",
    "\n",
    "def predict_test_img(path):\n",
    "    img = cv2.imread(path) \n",
    "    \n",
    "    model = load_model('./bin/mobilenetv2_class20.h5')\n",
    "    \n",
    "    print('Original Shape : ',img.shape)\n",
    "    \n",
    "    img = cv2.resize(img, (224,224), fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img / 255\n",
    "    print('Resized Shape : ',img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    ans = model.predict_classes(np.expand_dims(img,axis=0))\n",
    "    with open('./bin/class20.pickle','rb') as f:\n",
    "        class20 = pickle.load(f)\n",
    "    print('Predict : {}'.format(class20[ans[0]]))\n",
    "    \n",
    "    predicted_result = model.predict(np.expand_dims(img,axis=0))\n",
    "\n",
    "    pd.DataFrame(predicted_result,columns=class20.values()).iloc[0].plot(kind='bar')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:45:43.591984Z",
     "start_time": "2019-12-02T14:45:33.879543Z"
    }
   },
   "outputs": [],
   "source": [
    "# 기존에 사용되지 않았던 임의 데이터를 추론 하기\n",
    "\n",
    "predict_test_img('img/test/dog.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:46:16.431204Z",
     "start_time": "2019-12-02T14:46:06.078002Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test_img('img/test/boat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:46:28.033589Z",
     "start_time": "2019-12-02T14:46:16.432395Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test_img('img/test/cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:46:40.847973Z",
     "start_time": "2019-12-02T14:46:28.034954Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test_img('img/test/sofa.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:46:54.872957Z",
     "start_time": "2019-12-02T14:46:40.849078Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test_img('img/test/aeroplane.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-02T14:47:10.156559Z",
     "start_time": "2019-12-02T14:46:54.873998Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_test_img('img/test/person_bike.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intel OpenVINO\n",
    "    - https://software.intel.com/en-us/openvino-toolkit\n",
    "- Tensorflow\n",
    "    - https://www.tensorflow.org/?hl=ko\n",
    "- Keras\n",
    "    - https://keras.io/\n",
    "    - https://tensorflow.blog/2019/03/06/tensorflow-2-0-keras-api-overview/\n",
    "    - https://tykimos.github.io/2017/02/22/Integrating_Keras_and_TensorFlow/\n",
    "    - https://tykimos.github.io/2017/03/08/CNN_Getting_Started/\n",
    "    - https://raw.githubusercontent.com/keras-team/keras-docs-ko/master/sources/why-use-keras.md\n",
    "- Keras to Caffe\n",
    "     - https://github.com/uhfband/keras2caffe\n",
    "     - http://www.deepvisionconsulting.com/from-keras-to-caffe/\n",
    "- Fully Connected Layer\n",
    "    - https://sonofgodcom.wordpress.com/2018/12/31/cnn%EC%9D%84-%EC%9D%B4%ED%95%B4%ED%95%B4%EB%B3%B4%EC%9E%90-fully-connected-layer%EB%8A%94-%EB%AD%94%EA%B0%80/\n",
    "- Convultional Nueral Network\n",
    "    - http://aikorea.org/cs231n/convolutional-networks/\n",
    "    - http://cs231n.stanford.edu/\n",
    "- CNN Models\n",
    "    - https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/\n",
    "\n",
    "- VOC2012\n",
    "    - https://blog.godatadriven.com/rod-keras-multi-label\n",
    "    - https://gist.github.com/rragundez/ae3a17428bfec631d1b35dcdc6296a85#file-multi-label_classification_with_keras_imagedatagenerator-ipynbhttps://fairyonice.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html\n",
    "    - http://research.sualab.com/introduction/2017/11/29/image-recognition-overview-1.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "강의목차",
   "title_sidebar": "강의목차",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
